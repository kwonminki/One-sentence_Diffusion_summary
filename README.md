[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)

# One-Sentence_Diffusion_summary
The repo for studying and sharing diffusion models. (Korean) \
Computer Vision with Diffusion models

Thanks to ì •ì¬ì„, ë°•ìš©í˜„ ğŸ¥°

Update ì•ŒëŒìš© ë””ìŠ¤ì½”ë“œ (ì—…ë°ì´íŠ¸ë˜ë©´ ë©”ì„¸ì§€ê°€ ë‚ ì•„ì˜µë‹ˆë‹¤.) \
Discord : https://discord.gg/7Wt8DqpsPU  (A message will be sent when updated)

## New updated

<details>
  <summary>In the last month</summary>
  
  ### 10 Mar. 2023
  **On Calibrating Diffusion Probabilistic Models**\
  *Tianyu Pang, Cheng Lu, Chao Du, Min Lin, Shuicheng Yan, Zhijie Deng*\
  arXiv 2023. [[Paper](https://arxiv.org/abs/2302.10688)] [[Code](https://github.com/thudzj/Calibrated-DPMs)]\
  [Submitted on 21 Feb 2023]\
  ê° ìŠ¤í…ì—ì„œ ì˜ˆì¸¡ëœ ìŠ¤ì½”ì–´ì˜ í•©ì´ 0ì´ ë˜ì–´ì•¼ í•œë‹¤ê³  ì£¼ì¥. ì´ë¥¼ ìœ„í•´ì„œ Theorem 1ì„ ì œì•ˆí•˜ëŠ”ë°, âˆ€0â‰¤s<tâ‰¤T ì¼ë•Œ sì—ì„œ êµ¬í•œ ìŠ¤ì½”ì–´ì™€ tì—ì„œ êµ¬í•œ ìŠ¤ì½”ì–´ê°€ ê°™ë‹¤ëŠ” ë§ì„ í•œë‹¤. -(xs|xt)ì¼ë•Œ- ìš©í˜„ë‹˜ì˜ ìƒê°ì€ ì´ Theorem 1ì´ DDIMì´ ì™œ ì˜ ë™ì‘í•˜ëŠ”ì§€ ë³´ì—¬ì£¼ê³  ìˆìœ¼ë©°, gDDIMì—ì„œ ì£¼ì¥í•˜ëŠ” ë°”ì™€ë„ ì—°ê´€ëœë‹¤ê³  í‰ê°€í•˜ì‹¬. ì´ë¥¼ í™•ì¥í•˜ì—¬ x0ì˜ ìŠ¤ì½”ì–´ì˜ í‰ê· ì´ 0ì´ë‹ˆ xtì˜ ìŠ¤ì½”ì–´ì˜ í‰ê· ì´ 0ì´ì–´ì•¼ í•œë‹¤ëŠ” ì£¼ì¥ì„ í•œë‹¤. (Eq.13) ì´ê±´ ê³µê° ëª»í•˜ì…¨ë‹¤. ì´ë¥¼ ë§Œì¡±ì‹œí‚¬ ìˆ˜ ìˆëŠ” ì˜ˆíƒ€të¥¼ ìŠ¤ì½”ì–´ì— ë„£ëŠ” ë°©ë²•ì„ ì œì•ˆí–ˆê³ , ì´ë¥¼ í†µí•´ DPM-Solverì˜ ì„±ëŠ¥ì„ ëª¨ë“  NFEì—ì„œ ì˜¬ë ¸ë‹¤.

**Improving Score-based Diffusion Models by Enforcing the Underlying Score Fokker-Planck Equation**\
*Chieh-Hsin Lai, Yuhta Takida, Naoki Murata, Toshimitsu Uesaka, Yuki Mitsufuji, Stefano Ermon*\
NeurIPS 2022 Workshop. [[Paper](https://arxiv.org/abs/2210.04296)]\
Submitted on 9 Oct 2022 (v1)\
Fokker-Planck Equationsì€ ë¸Œë¼ìš´ìš´ë™ì—ì„œ í•œ ìƒ˜í”Œì˜ ì›€ì§ì„ì´ ì•„ë‹ˆë¼ ì „ì²´ distributionì´ ì–´ë–»ê²Œ ì›€ì§ì´ì§€ëŠ”ì§€ì— ê´€ë ¨ëœ ìˆ˜ì‹ì´ë‹¤. ì´ë¥¼ Eq.6ì—ì„œ ë³´ì—¬ì£¼ê³  ìˆëŠ”ë°, t~=0 ì¼ ë•Œ Fokker-Planck Equationsì— ìœ„ë°˜ë˜ëŠ” ëª¨ìŠµì´ ë³´ì—¬ì§„ë‹¤ê³  ì£¼ì¥í•œë‹¤. ì´ë¥¼ ê°ë§ˆFP í…€ì„ ê°€ì§€ê³  ì¡°ì ˆí•´ì¤˜ì„œ ë§ì¶°ì£¼ëŠ”ë°, ì‹¤í—˜ì´ ë§ì§€ëŠ” ì•Šë‹¤. ì›Œí¬ìƒµ í˜ì´í¼ì´ë‹¤.
  
  
  ### 24 Feb 2023
  **MagicVideo: Efficient Video Generation With Latent Diffusion Models**\
  *Daquan Zhou, Weimin Wang, Hanshu Yan, Weiwei Lv, Yizhe Zhu, Jiashi Feng*\
  arXiv 2023. [[Paper](https://arxiv.org/abs/2211.11018)] [[Project Page](https://magicvideo.github.io/#)]\
  [Submitted on 20 Nov 2022]\
  ë¹„ë””ì˜¤ë¥¼ ê°€ì§€ê³  í›ˆë ¨ì‹œí‚¤ëŠ” ë°, adaptor ë¼ëŠ” ê°œë…ì„ ì¶”ê°€í•˜ì—¬, frame ê°„ì˜ ê´€ê³„ ì •ë³´ë¥¼ ê³µìœ í•˜ë„ë¡ í•œë‹¤. ì´ ë•Œ Directed Temporal Attention ì„ ì‚¬ìš©í•´ì„œ - Masked Self attentionê³¼ ê±°ì˜ ë™ì¼í•œ ê°œë….- ë’¤ìª½ frameì—ê²Œë§Œ ì˜í–¥ì„ ë¼ì¹˜ë„ë¡ ë§Œë“¬. ë‚˜ì˜ì§€ ì•Šì€ ë…¼ë¬¸.
  
  **SmartBrush: Text and Shape Guided Object Inpainting with Diffusion Model**\
  *Shaoan Xie, Zhifei Zhang, Zhe Lin, Tobias Hinz, Kun Zhang*\
  arXiv 2022. [[Paper](https://arxiv.org/abs/2212.05034)]\
  [Submitted on 9 Dec 2022]\
  ë§ˆìŠ¤í¬ë¥¼ ì£¼ë©´ ê±°ê¸°ì— í…ìŠ¤íŠ¸ì— í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€ ìƒì„±. ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ë¸ì„ í›ˆë ¨ì„ ì‹œí‚¤ëŠ”ë°, ë§ˆìŠ¤í¬ì— ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ì»¤ë„ì„ í†µê³¼ì‹œí‚¤ê³ , ìƒì„±ë˜ëŠ” ì´ë¯¸ì§€ì—ì„œ ë§ˆìŠ¤í¬ë¥¼ predict í•˜ê²Œ í•˜ì—¬ predictëœ ë§ˆìŠ¤í¬ ì˜ì—­ë§Œ ëŒ€ì²´í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ backgroundë¥¼ ìµœëŒ€í•œ ì§€í‚¨ë‹¤. ì‹¤ì œë¡œ ìƒì„± ì˜ì—­ì„ ë„“ê²Œ ì¡ì•„ë„ backgroundê°€ ìƒë‹¹íˆ ì˜ ìœ ì§€ëœë‹¤.
  
  **Boundary Guided Mixing Trajectory for Semantic Control with Diffusion Models**\
  *Ye Zhu, Yu Wu, Zhiwei Deng, Olga Russakovsky, Yan Yan*\
  arXiv 2023. [[Paper](https://arxiv.org/abs/2212.05034)]\
  [Submitted on 16 Feb 2023]\
  Asyrpì„ ì‚¬ìš©í•˜ë©´ (Diffusion models already have a semantic latent space) ìƒê¸°ëŠ” ë¬¸ì œë¥¼ inversion ì´ë¯¸ì§€ì™€ generated ì´ë¯¸ì§€ì˜ xT ë¶„í¬ë¥¼ ê°€ì§€ê³  ë¶„ì„í•¨. inversioní•œ ì´ë¯¸ì§€ê°€ ê°€ìš°ì‹œì•ˆ ë¶„í¬ ê»ì§ˆ ì•ˆìª½ì— ìˆë‹¤ê³  ë§í•˜ê³ , ì´ê±¸ ë§ì¶°ì£¼ëŠ” ë°©ì‹ì„ ì œì•ˆí•¨. - ì œëŒ€ë¡œ ì•ˆì½ì–´ì„œ ì¶”í›„ ì—…ë°ì´íŠ¸ ì˜ˆì •.
  
  ### 16 Feb 2023
  
  **Structure and Content-Guided Video Synthesis with Diffusion Models**\
  *Patrick Esser, Johnathan Chiu, Parmida Atighehchian, Jonathan Granskog, Anastasis Germanidis*\
  arXiv 2023. [[Paper](https://arxiv.org/abs/2302.03011)] [[Project Page](https://research.runwayml.com/gen1)]\
  [Submitted on 6 Feb 2023] \
  ë¹„ë””ì˜¤2ë¹„ë””ì˜¤ translationì„ í•  ë•Œ, ì´ë¯¸ ë˜ëŠ” í…ìŠ¤íŠ¸ë¡œ ê°€ì´ë“œë¥¼ ì£¼ëŠ” ë…¼ë¬¸. ë¹„ë””ì˜¤ì˜ timeì— ë”°ë¥¸ Spatio-temporalì„ ìœ„í•´ temporal convolution/attention ë„¤íŠ¸ì›Œí¬ë¥¼ ì‚½ì…í•˜ì˜€ê³ , structureë¥¼ ìœ ì§€ì‹œí‚¤ê¸° ìœ„í•´ depth estimation ì„ ì‚¬ìš©í•˜ì˜€ìŒ. ë˜í•œ í›ˆë ¨ë•Œ ì‚¬ìš©í•œ ë¹„ë””ì˜¤ë¥¼ CLIP image encoderì— íƒœì›Œ, ê¸°ì¡´ í…ìŠ¤íŠ¸ ëŒ€ì‹  imageë¡œ conditionì„ ì¤„ ìˆ˜ ìˆë„ë¡ í›ˆë ¨í•¨. 
  
  **Zero-shot Image-to-Image Translation**\
*Gaurav Parmar, Krishna Kumar Singh, Richard Zhang, Yijun Li, Jingwan Lu, Jun-Yan Zhu*\
arXiv 2023. [[Paper](https://arxiv.org/abs/2302.03027)] \
6 Feb 2022 \
ë³„ë„ì˜ user prompt ì—†ì´ source word(eg. dog) ì™€ target word(e.g. cat) ë§Œ ê°€ì§€ê³  image translationí•˜ëŠ” ë…¼ë¬¸. í•´ë‹¹ ë‹¨ì–´ê°€ í¬í•¨ëœ ì—¬ëŸ¬ê°œì˜ ë¬¸ì¥ì˜ CLIP embedding ê°„ì˜ ì°¨ì´ë¥¼ editing directionìœ¼ë¡œ ì„¤ì •í•˜ì—¬ inference í• ë•Œ text conditionì— directionë§Œ ë”í•˜ì—¬ editing ê°€ëŠ¥, input imageì˜ content structure ìœ ì§€ë¥¼ ìœ„í•´ì„œ cross attention guidanceë¥¼ ì œì‹œ(contentì™€ backgroundìœ ì§€ êµ¿), gaussian distributionìœ ì§€ë¥¼ ìœ„í•œ autocorrelation regularization ì œì•ˆ. 

  **Progressive Distillation for Fast Sampling of Diffusion Models**\
  *Tim Salimans, Jonathan Ho*\
  arXiv 2022. [[Paper](https://arxiv.org/abs/2202.00512)] \
  Faster sampling ì„ ëª©í‘œë¡œ, denoising 2 step ì„ ì˜ˆì¸¡í•˜ëŠ” student ëª¨ë¸ì„ í•™ìŠµì‹œí‚¨ë‹¤. ì´ë•Œ, $\epsilon$-prediction ì„ í•˜ê²Œ ë  ê²½ìš° ê¸°ì¡´ê³¼ëŠ” ë‹¬ë¦¬ numerical error ì— ëŒ€í•œ correction ì´ ì´ë¤„ì§ˆ ìˆ˜ ì—†ì–´ì„œ v-prediction ì´ë¼ëŠ” ìƒˆë¡œìš´ parameterization ì„ ì œì•ˆí•¨. (v-prediction ì€ ìƒê°ë³´ë‹¤ ìì£¼ ì“°ì´ë‹ˆ Appendix D ëŠ” ë³´ê¸°ë¥¼ ì¶”ì²œ)

  **Zero-Shot Image Restoration Using Denoising Diffusion Null-Space Model**\
  *Yinhuai Wang, Jiwen Yu, Jian Zhang*\
  arXiv 2022. [[Paper](https://arxiv.org/abs/2212.00490)] \
  Linear Degradation $\mathbf{A}$ ë¥¼ ì•Œê³  ìˆì„ë•Œ, Realness restoration ì„ $\mathbf{A}$ ì˜ null-space ì—ì„œë§Œ ì§„í–‰í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆ. ì‹¤ì§ˆì ì¸ ì´ë¯¸ì§€ í€„ë¦¬í‹° í–¥ìƒì€ Repaint ì—ì„œ ì œì•ˆëœ time-travel ê¸°ë²•ì„ í†µí•´ ì´ë¤„ì¡Œë‹¤. 
  
  **Adding Conditional Control to Text-to-Image Difusion Models**\
  *Lvmin Zhang, Maneesh Agrawala*\
  [[Code](https://github.com/lllyasviel/ControlNet)] \
  ì–´ë–¤ condition ì´ë“  í•™ìŠµí•  ìˆ˜ ìˆëŠ” ControlNet ì„ ì œì•ˆ. Stable Diffusion encoder ì˜ copy ë¥¼ hypernetwork ì²˜ëŸ¼ í™œìš©í•˜ë˜, í•™ìŠµì˜ ì•ˆì •ì„±ì„ ìœ„í•´ zero-conv ë¥¼ ë„ì…í•œë‹¤. 
  
  ### 06 Feb 2023
  
  **Minimizing Trajectory Curvature of ODE-based Generative Models** \
  *Sangyun Lee, Beomsu Kim, Jong Chul Ye*\
  arxiv 27 Jan 2023 [[Paper](https://arxiv.org/abs/2301.12003)]\
  sampling trajectoryì˜ curvatureë¥¼ ì¤„ì—¬ì„œ í•™ìŠµëœ denoising modelì— ode solver ê°€ fit í•˜ë„ë¡ ë§Œë“¤ê³ , ì ì€ stepì—ì„œë„ generation, reconstructionì´ ì˜ ë˜ë„ë¡ ì‹œë„í•¨

  ### 02 Feb 2023

  **GLIGEN: Open-Set Grounded Text-to-Image Generation** \
  *Yuheng Li, Haotian Liu, Qingyang Wu, Fangzhou Mu, Jianwei Yang, Jianfeng Gao, Chunyuan Li, Yong Jae Lee* \
  arXiv 2023. [[Paper](https://arxiv.org/abs/2301.07093)]\
  [Submitted on 17 Jan 2023]\
  Stable diffusionì€ freeze í•´ ë‘” ì±„ë¡œ self attentionê³¼ cross attention ì‚¬ì´ì— Gated Self attention layerë¥¼ ì¶”ê°€í•˜ì—¬ í•™ìŠµ. Bounding boxì™€ ìº¡ì…˜, key point(ìŠ¤ì¼ˆë ˆí†¤), ì´ë¯¸ì§€ ê°€ì´ë“œë¡œ ì›í•˜ëŠ” ìœ„ì¹˜ì— ì›í•˜ëŠ” ìƒ˜í”Œì„ ë„£ì„ ìˆ˜ ìˆìŒ. ì˜ë˜ê³ , ì‹¤í—˜ ì—„ì²­ ë§ì´ í•´ì¤Œ. ì¤‘ê°„ì— layer ë„£ëŠ”ë‹¤ëŠ” ì ì´ ë§ˆìŒì— ë“¬.

  **On distillation of guided diffusion models** \
  *Chenlin Meng, Robin Rombach, Ruiqi Gao, Diederik P. Kingma, Stefano Ermon, Jonathan Ho, Tim Salimans* \
  arXiv 2022. [[Paper](https://arxiv.org/abs/2210.03142)]\
  ë‘ë²ˆì˜ distillation ìœ¼ë¡œ step ì„ 1~4 step ìœ¼ë¡œ ë¹„ì•½ì ìœ¼ë¡œ ì¤„ì¸ë‹¤. LDM ì˜ ê²½ìš° 1 step ê¹Œì§€ ê°€ëŠ¥í•˜ë‹¤. \
  stage 1. classifier-free guidance ì˜ score ì— ëŒ€í•œ student ëª¨ë¸ í•™ìŠµ. \
  stage 2. progressive-distillation ì„ í†µí•´ step ìˆ˜ë¥¼ N/2 ìœ¼ë¡œ ê³„ì† ì¤„ì—¬ë‚˜ê°.
  
  **On the Importance of Noise Scheduling for Diffusion Models** \
  *Ting Chen* \
  arXiv 2023. [[Paper](https://arxiv.org/abs/2301.10972)]\
  high resolution ì—ì„œëŠ” ê°™ì€ SNR ì—ì„œë„ ì´ë¯¸ì§€ê°€ ëœ ë§ê°€ì§€ëŠ” ê²ƒìœ¼ë¡œë¶€í„°, resolution ë³„ ìƒˆë¡œìš´ noise scheduling ì„ ì œì•ˆí•¨. \
  ì´ë¯¸ì§€ê°€ í´ìˆ˜ë¡ ì •ë³´ê°€ ì‚´ì•„ë‚¨ëŠ” ê²ƒìœ¼ë¡œë¶€í„° ì°©ì•ˆí•˜ì—¬, signal ì„ ë‚®ì¶°ì£¼ëŠ” $xt=\sqrt{\alpha} b x_0 + \sqrt{1 - \alpha} \epsilon ì„ ì œì•ˆ.\
  +) UNet backbone ì´ ì•„ë‹™ë‹ˆë‹¤.
  
  **EDICT: Exact Diffusion Inversion via Coupled Transformations** \
  *Bram Wallace, Akash Gokul, Nikhil Naik* \
  arXiv 2022. [[Paper](https://arxiv.org/abs/2211.12446)]\
  DDIM inversion ê³¼ Normalizing flow ì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” Affine coupling layer ì˜ ìˆ˜ì‹ì´ ë™ì¼í•˜ë‹¤ëŠ” ì ì—ì„œ ì°©ì•ˆí•˜ì—¬, ì™„ë²½í•˜ê²Œ inversion ë˜ëŠ” process ë¥¼ ì œì•ˆ. \
  text-conditional ì¼ë•Œë‚˜ guidance scale ì´ í´ë•Œë„ reconstruction ì„±ëŠ¥ì´ ì¢‹ìŠµë‹ˆë‹¤.
  

  

</details>


## Contents
- [Resources](#resources)
  - [Introductory Posts](#introductory-posts)
  - [Introductory Papers](#introductory-papers)
  - [Introductory Videos](#introductory-videos)
- [Papers](#papers)
  - [Must-read papers](#must-read-papers)
  - [Stable diffusion freeze](#stable-diffusion-freeze)
  - [Stable diffusion finetuning](#stable-diffusion-finetuning)
  - [Connection with other framworks](#connection-with-other-framworks)
  - [Image Generation](#image-generation)
  - [Image space guidance sampling](#image-space-guidance-sampling)
  - [Classifier guidance sampling](#classifier-guidance-sampling)
  - [Image Editing](#image-editing)
  - [Text-focused](#text-focused)
  - [Fast Sampling](#fast-sampling)
  - [Video Generation](#video-generation)
  - [3D](#3d)
  - [ìˆ˜í•™ê¸°ë°˜í–¥ìƒ](#ìˆ˜í•™ê¸°ë°˜í–¥ìƒ)
  - [ê¸°íƒ€](#ê¸°íƒ€)
    
  
# Resources
## Introductory Posts

**What are Diffusion Models?** \
[[Website](https://lilianweng.github.io/lil-log/2021/07/11/diffusion-models.html)] \
11 Jul 2021 \
ì „ë°˜ì ì¸ Generative ëª¨ë¸ì— ëŒ€í•œ ì†Œê°œì™€ Diffusion modelì˜ ìˆ˜ì‹ì ì¸ ì •ë¦¬ê°€ ê¹”ë”í•˜ê²Œ ë˜ì–´ìˆìŒ. ë³µìˆ­ì•„ ì•„ì´ì½˜ ì‚¬ì´íŠ¸.

**Generative Modeling by Estimating Gradients of the Data Distribution** \
[[Website](https://yang-song.github.io/blog/2021/score/)] \
5 May 2021 \
Yang Song ë¸”ë¡œê·¸. Score-based modelsë¥¼ ê¸°ì¡´ì˜ MCMC ë¶€í„° ì‹œì‘í•˜ì—¬ ì°¨ê·¼ì°¨ê·¼ í›‘ì–´ì¤Œ. ì¶”ì²œ.

## Introductory Papers

**Understanding Diffusion Models: A Unified Perspective** \
*Calvin Luo* \
arXiv 2022. [[Paper](https://arxiv.org/abs/2208.11970)] \
25 Aug 2022 \
ê¸°ì¡´ Diffusion ë…¼ë¬¸ë“¤ì˜ notationì´ ë‹¤ ë‹¬ë¼ì„œ í˜ë“ ë°, ì´ ë…¼ë¬¸ì´ ì „ì²´ì ì¸ ì •ë¦¬ë¥¼ ì‹¹ ë‹¤ í•´ë†“ìŒ. êµ¬ê¸€ì—ì„œ ì¼ê³ , VAEì—ì„œ ë¶€í„° classifier guidanceê¹Œì§€ ìˆ˜ì‹ì ìœ¼ë¡œë„ ì´ì •ë¦¬ í•´ë‘ . ìˆ˜í•™ ì¦ëª…ì´ ì•ˆë˜ëŠ” ë¶€ë¶„ì´ ìˆë‹¤ë©´ ì°¸ê³ í•˜ê¸° ì¢‹ìŒ.

**A Survey on Generative Diffusion Model** \
*Hanqun Cao, Cheng Tan, Zhangyang Gao, Guangyong Chen, Pheng-Ann Heng, Stan Z. Li* \
arXiv 2022. [[Paper](https://arxiv.org/abs/2209.02646)] \
6 Sep 2022 \
Survey.

**Diffusion Models: A Comprehensive Survey of Methods and Applications** \
*Ling Yang, Zhilong Zhang, Shenda Hong, Wentao Zhang, Bin Cui* \
arXiv 2022. [[Paper](https://arxiv.org/abs/2209.00796)] \
9 Sep 2022 \
Survey.

## Introductory Videos
*ì´ìƒìœ¤*\
[[Youtube channel](https://www.youtube.com/channel/UC0xHseqVPJCGy1oNIfJA4VQ)] \
ë””í“¨ì „ê´€ë ¨ ìŠ¤í„°ë”” ì˜ìƒì„ ì—…ë¡œë“œ í•´ì¤€ ì±„ë„. ì•„ì‰½ê²Œë„ 2022.08 ì¦ˆìŒë¶€í„° ë©ˆì¶”ê¸´ í–ˆì§€ë§Œ í•œêµ­ë§ ì„¤ëª…ì´ë¼ ì°¾ì•„ë³´ë©´ ì¢‹ìŒ.

*ë””í“¨ì „ ì „ë°˜ì ì¸ ì •ë¦¬ì˜ìƒ*\
[[Youtube](https://youtu.be/uFoGaIVHfoE)] \
ì œê°€ ë°œí‘œí•œ ì˜ìƒì…ë‹ˆë‹¤. DDPM, DDIM, ADM-G, NCSN, Score-based models, ê·¸ë¦¬ê³  ì—¬ëŸ¬ ëª¨ë¸ë“¤ì˜ íë¦„ê³¼ ìˆ˜í•™ì„ ì´ì •ë¦¬ í–ˆìŠµë‹ˆë‹¤.

# Papers


## Must-read papers

**Deep Unsupervised Learning using Nonequilibrium Thermodynamics** \
*Jascha Sohl-Dickstein, Eric A. Weiss, Niru Maheswaranathan, Surya Ganguli* \
ICML 2015. [[Paper](https://arxiv.org/abs/1503.03585)] [[Github](https://github.com/Sohl-Dickstein/Diffusion-Probabilistic-Models)] \
2 Mar 2015 \
Diffusionì˜ ì‹œì‘. Reverse diffusion processë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ë³µêµ¬í•˜ëŠ” ë°©ì‹ì„ ì œì•ˆí•¨. ê°ê°ì˜ time step ë³„ ê°€ìš°ì‹œì•ˆ ë¶„í¬ë¥¼ reparameterize í•˜ëŠ” ë°©ì‹ì˜ ì‹œì´ˆë¼ê³  í•  ìˆ˜ ìˆë‹¤. í•˜ì§€ë§Œ ì•ˆì½ì–´ë„ í° ë¬¸ì œëŠ” ì—†ìŒ. (DDPMì„ ì´í•´í–ˆë‹¤ëŠ” ì „ì œí•˜ì—)

**Denoising Diffusion Probabilistic Models** \
*Jonathan Ho, Ajay Jain, Pieter Abbeel* \
NeurIPS 2020. [[Paper](https://arxiv.org/abs/2006.11239)] [[Github](https://github.com/hojonathanho/diffusion)] [[Github2](https://github.com/pesser/pytorch_diffusion)] \
19 Jun 2020 \
DDPM. ì½ì–´ì•¼ í•¨. xtë¥¼ x0ë¥¼ ê°€ì§€ê³  ë°”ë¡œ ìƒ˜í”Œë§í•˜ëŠ” ë°©ì‹ ì œì•ˆ, Lossë¥¼ simpleí•˜ê²Œ ë§Œë“¤ì–´ë„ ì˜ ëœë‹¤ëŠ” ê²ƒì„ ë³´ì„.

**Improved Denoising Diffusion Probabilistic Models** \
*Alex Nichol<sup>1</sup>, Prafulla Dhariwal<sup>1</sup>* \
ICLR 2021. [[Paper](https://arxiv.org/abs/2102.09672)] [[Github](https://github.com/openai/improved-diffusion)] \
18 Feb 2021 \
ì‚¬ì‹¤ í•„ìˆ˜ë¡œ ì½ì–´ì•¼ í•˜ëŠ” ë…¼ë¬¸ê¹Œì§€ëŠ” ì•„ë‹˜. ì•„í‚¤í…ì²˜ì˜ ë³€í™”ì™€ ìŠ¤ì¼€ì¤„ë§ì˜ ë³€í™”ë¥¼ ì¤Œ. í•˜ì§€ë§Œ ì—¬ê¸°ì €ê¸°ì„œ ë§ì´ ë“±ì¥í•˜ë¯€ë¡œ ì½ì–´ë‘ë©´ ì¢‹ìŒ. ì¤‘ìš”ë„ëŠ” ê·¸ë¦¬ ë†’ì§€ ì•ŠìŒ.

**Diffusion Models Beat GANs on Image Synthesis** \
*Prafulla Dhariwal<sup>1</sup>, Alex Nichol<sup>1</sup>* \
arXiv 2021. [[Paper](https://arxiv.org/abs/2105.05233)] [[Github](https://github.com/openai/guided-diffusion)] \
11 May 2021 \
Classifier guidance ë°©ì‹ì„ ì œì•ˆí•œ ë…¼ë¬¸. ì •ë§ ë§ì´ ì“°ì´ê³  ìˆìœ¼ë©° ì½ì–´ë‘ëŠ” ê²ƒì„ ì¶”ì²œ.

**Denoising Diffusion Implicit Models**  \
*Jiaming Song, Chenlin Meng, Stefano Ermon* \
ICLR 2021. [[Paper](https://arxiv.org/abs/2010.02502)] [[Github](https://github.com/ermongroup/ddim)] \
6 Oct 2020 \
Marcov chainì„ ëŠê³  Deterministic í•˜ê²Œ ë§Œë“  ë…¼ë¬¸. ìˆ˜ì‹ì ìœ¼ë¡œ ë³µì¡í•˜ë‚˜, ì˜ ì´í•´í•´ë‘¬ì•¼ í•˜ëŠ” í•„ìˆ˜ ë…¼ë¬¸ ì¤‘ í•˜ë‚˜.

**Generative Modeling by Estimating Gradients of the Data Distribution** \
*Yang Song, Stefano Ermon* \
NeurIPS 2019. [[Paper](https://arxiv.org/abs/1907.05600)] [[Project](https://yang-song.github.io/blog/2021/score/)] [[Github](https://github.com/ermongroup/ncsn)] \
12 Jul 2019 \
Score-based modelsì˜ ì‹œì´ˆê²©ì¸ ë…¼ë¬¸. ê²°êµ­ VE-SDEë¥¼ ì´í•´í•˜ê¸° ìœ„í•´ì„  ì´ ë…¼ë¬¸ì´ ì„ í–‰ë˜ì–´ì•¼ í•¨.

**Score-Based Generative Modeling through Stochastic Differential Equations** \
*Yang Song, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano Ermon, Ben Poole* \
ICLR 2021 (Oral). [[Paper](https://arxiv.org/abs/2011.13456)] [[Github](https://github.com/yang-song/score_sde)] \
26 Nov 2020 \
Score-based ì™€ DDPMì„ SDEë¡œ ë¬¶ì–´ë‚¸ ë…¼ë¬¸. ë§¤ìš° ì˜ ì¨ì§„ ë…¼ë¬¸ì´ë¼ ìƒê°í•˜ë©°, í•„ìˆ˜ì ìœ¼ë¡œ ì½ì–´ë´ì•¼ í•œë‹¤ê³  ìƒê°.

**Variational Diffusion Models** \
*Diederik P. Kingma, Tim Salimans, Ben Poole, Jonathan Ho* \
NeurIPS 2021. [[Paper](https://arxiv.org/abs/2107.00630)] [[Github](https://github.com/revsic/jax-variational-diffwave)] \
1 Jul 2021 \
í•„ìˆ˜ë¼ê³  ì ì–´ë†¨ì§€ë§Œ í•„ìë„ ì•„ì§ ì•ˆì½ì—ˆìŠµë‹ˆë‹¤.. SNRì„ ì •ì˜ ë‚´ë¦° ë…¼ë¬¸. ê·¸ë¦¬ê³  ìˆ˜ì‹ì ìœ¼ë¡œ ì˜ ì •ë¦¬ëœ ë…¼ë¬¸. ì¡°ë§Œê°„ ì½ê³  ì—…ë°ì´íŠ¸ í•˜ê² ìŠµë‹ˆë‹¤.

**Elucidating the Design Space of Diffusion-Based Generative Models** \
*Tero Karras, Miika Aittala, Timo Aila, Samuli Laine* \
arXiv 2022. [[Paper](https://arxiv.org/abs/2206.00364)] \
1 Jun 2022 \
ì‹¤í—˜ì ìœ¼ë¡œ Diffusion modelì„ ì–´ë–»ê²Œ ì„¤ê³„í•˜ëŠ” ê²ƒì´ ì¢‹ì€ì§€ ì˜ ì •ë¦¬í•´ë†“ì€ ë…¼ë¬¸.

**Classifier-Free Diffusion Guidance** \
*Jonathan Ho, Tim Salimans* \
NeurIPS Workshop 2021. [[Paper](https://arxiv.org/abs/2207.12598)] \
28 Sep 2021 \
GANìœ¼ë¡œ ì¹˜ë©´ condition GAN. ì™¸ë¶€ì—ì„œ classifierë¡œ guidanceë¥¼ ì£¼ëŠ” ëŒ€ì‹ , UNetì— ë°”ë¡œ ì»¨ë””ì…˜ì„ ê½‚ì•„ì¤Œ. ì´ ë•Œ ìˆ˜ì‹ì„ classifier guidanceë‘ ê°™ì•„ì§€ë„ë¡ ì „ê°œ, ì˜ ë¨. í˜„ì¬ ì˜ ë˜ëŠ” ëŒ€ë¶€ë¶„ì˜ ëª¨ë¸ë“¤ì€ free guidance ë°©ì‹ìœ¼ë¡œ í•™ìŠµë¨.

## Stable Diffusion Freeze

**Adding Conditional Control to Text-to-Image Difusion Models**\
*Lvmin Zhang, Maneesh Agrawala*\
[[Code](https://github.com/lllyasviel/ControlNet)] \
ì–´ë–¤ condition ì´ë“  í•™ìŠµí•  ìˆ˜ ìˆëŠ” ControlNet ì„ ì œì•ˆ. Stable Diffusion encoder ì˜ copy ë¥¼ hypernetwork ì²˜ëŸ¼ í™œìš©í•˜ë˜, í•™ìŠµì˜ ì•ˆì •ì„±ì„ ìœ„í•´ zero-conv ë¥¼ ë„ì…í•œë‹¤. 

**Zero-shot Image-to-Image Translation**\
*Gaurav Parmar, Krishna Kumar Singh, Richard Zhang, Yijun Li, Jingwan Lu, Jun-Yan Zhu*\
arXiv 2023. [[Paper](https://arxiv.org/abs/2302.03027)] \
6 Feb 2022 \
ë³„ë„ì˜ user prompt ì—†ì´ source word(eg. dog) ì™€ target word(e.g. cat) ë§Œ ê°€ì§€ê³  image translationí•˜ëŠ” ë…¼ë¬¸. í•´ë‹¹ ë‹¨ì–´ê°€ í¬í•¨ëœ ì—¬ëŸ¬ê°œì˜ ë¬¸ì¥ì˜ CLIP embedding ê°„ì˜ ì°¨ì´ë¥¼ editing directionìœ¼ë¡œ ì„¤ì •í•˜ì—¬ inference í• ë•Œ text conditionì— directionë§Œ ë”í•˜ì—¬ editing ê°€ëŠ¥, input imageì˜ content structure ìœ ì§€ë¥¼ ìœ„í•´ì„œ cross attention guidanceë¥¼ ì œì‹œ(contentì™€ backgroundìœ ì§€ êµ¿), gaussian distributionìœ ì§€ë¥¼ ìœ„í•œ autocorrelation regularization ì œì•ˆ. 

**GLIGEN: Open-Set Grounded Text-to-Image Generation** \
*Yuheng Li, Haotian Liu, Qingyang Wu, Fangzhou Mu, Jianwei Yang, Jianfeng Gao, Chunyuan Li, Yong Jae Lee* \
arXiv 2023. [[Paper](https://arxiv.org/abs/2301.07093)]\
[Submitted on 17 Jan 2023]\
Stable diffusionì€ freeze í•´ ë‘” ì±„ë¡œ self attentionê³¼ cross attention ì‚¬ì´ì— Gated Self attention layerë¥¼ ì¶”ê°€í•˜ì—¬ í•™ìŠµ. Bounding boxì™€ ìº¡ì…˜, key point(ìŠ¤ì¼ˆë ˆí†¤), ì´ë¯¸ì§€ ê°€ì´ë“œë¡œ ì›í•˜ëŠ” ìœ„ì¹˜ì— ì›í•˜ëŠ” ìƒ˜í”Œì„ ë„£ì„ ìˆ˜ ìˆìŒ. ì˜ë˜ê³ , ì‹¤í—˜ ì—„ì²­ ë§ì´ í•´ì¤Œ. ì¤‘ê°„ì— layer ë„£ëŠ”ë‹¤ëŠ” ì ì´ ë§ˆìŒì— ë“¬.

**Null-text Inversion for Editing Real Images using Guided Diffusion Models** \
*Ron Mokady, Amir Hertz, Kfir Aberman, Yael Pritch, Daniel Cohen-Or* \
arXiv 2022. [[Paper](https://arxiv.org/abs/2211.09794)] \
17 Nov 2022 \
ë³„ë„ì˜ model fine-tuning ì—†ì´, real image ì— í•´ë‹¹í•˜ëŠ” null-textë¥¼ optimization í•˜ì—¬ prompt2prompt ë°©ì‹ìœ¼ë¡œ objectì˜ semantic detailì„ ìœ ì§€í•˜ë©´ì„œ image editingì„ ê°€ëŠ¥í•˜ê²Œí•¨. ë°©ë²• ì¢‹ì€ ê²°ê³¼ ì¢‹ì€. ê´œì°®ì€ ë…¼ë¬¸.

**DiffEdit: Diffusion-based semantic image editing with mask guidance** \
*Guillaume Couairon, Jakob Verbeek, Holger Schwenk, Matthieu Cord* \
Submitted to ICLR2023. [[Paper](https://arxiv.org/abs/2210.11427)] \
20 Oct 2022 \
Reference textì™€ query textê°€ ì£¼ì–´ì¡Œì„ë•Œ ë‘ í…ìŠ¤íŠ¸ë¥¼ ì ìš©í–ˆì„ë•Œì˜ noise estimates ì°¨ì´ë¡œ ë§ˆìŠ¤í¬ë¥¼ ìƒì„± - ìƒì„±í•œ ë§ˆìŠ¤í¬ë¥¼ í†µí•´ DDIM decodingê³¼ì •ì—ì„œ encodingëœ ê²ƒê³¼ ì ì ˆíˆ í•©ì³ì„œ text ë¶€ë¶„ë§Œ edití•˜ëŠ” ê°„ë‹¨í•œ ë°©ë²•.

**An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion** \
*Rinon Gal, Yuval Alaluf, Yuval Atzmon, Or Patashnik, Amit H. Bermano, Gal Chechik, Daniel Cohen-Or* \
arXiv 2022. ICLR2023 submission [[Paper](https://arxiv.org/abs/2208.01618)] \
[Submitted on 2 Aug 2022] \
ì´ë¯¸ì§€ 3~5ì¥ì„ S* ë¼ëŠ” ë¬¸ìë¡œ inversioní•œë‹¤. GAN inversionê³¼ ìœ ì‚¬. ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ê³¼ì •ì—ì„œ ë‚˜ì˜¤ëŠ” ë…¸ì´ì¦ˆì™€ given imageë¥¼ inversion í•˜ëŠ” ê³¼ì •ì—ì„œ ë‚˜ì˜¤ëŠ” ë…¸ì´ì¦ˆê°„ì˜ MSE lossë¥¼ ì‚¬ìš©í•˜ì—¬ "A photo of S*" ë¼ëŠ” promptì˜ S*ì— í•´ë‹¹í•˜ëŠ” í† í°ì„ ì§ì ‘ optimizeí•œë‹¤.


## Stable Diffusion Finetuning

**Paint by Example: Exemplar-based Image Editing with Diffusion Models** \
*Binxin Yang, Shuyang Gu, Bo Zhang, Ting Zhang, Xuejin Chen, Xiaoyan Sun, Dong Chen, Fang Wen* \
CVPR2023 submission. [[Paper](https://arxiv.org/abs/2211.13227)] \
[Submitted on 23 Nov 2022] \
ìœ ì €ê°€ ì§€ì •í•œ ì˜ì—­ì— ì»¨ë””ì…˜ìœ¼ë¡œ ì£¼ì–´ì§„ ì´ë¯¸ì§€ì˜ semanticì„ ìƒì„±í•œ ë…¼ë¬¸. 1. StableDiffusionìœ¼ë¡œ init 2. ì´ë¯¸ì§€ì˜ ë©”ì¸ ì˜¤ë¸Œì íŠ¸ íŒ¨ì¹˜ë¥¼ ë–¼ì–´ë‚´ê³ , CLIP ì´ë¯¸ì§€ ì¸ì½”ë”ì— augmentationí•´ì„œ ë„£ì–´ì¤€ë‹¤. ì´ ë•Œ CLIPì„ 1024ê¹Œì§€ ì„ë² ë”©ì„ ì‹œì¼œë²„ë¦¬ê³ , ì´ê±¸ ë‹¤ì‹œ ë¦¬ë‹ˆì–´ë ˆì´ì–´ ëª‡ê°œ í†µê³¼ì‹œì¼œì„œ ì»¨ë””ì…˜ìœ¼ë¡œ ë„£ì–´ì¤Œ. 3. 2ë²ˆì— ë”°ë¼ì„œ í•™ìŠµ.  ê²°ê³¼ ì¢‹ìŒ. ë°©ë²• ì¢‹ìŒ. ë…¼ë¬¸ ì˜ ì½í˜. ê´œì°®ì€ ë…¼ë¬¸.

**Multi-Concept Customization of Text-to-Image Diffusion** \
*Nupur Kumari, Bingliang Zhang, Richard Zhang, Eli Shechtman, Jun-Yan Zhu* \
arxiv Submitted on 8 Dec 2022\ preprint [[Paper](https://arxiv.org/abs/2212.04488)] 
 1)model ì¼ë¶€ë§Œ fine-tuning + 2) text optimization ì„ í†µí•´ì„œ Large text-to-image Diffusion modelì„ few-shot user images ìƒì—ì„œ customizing í•˜ëŠ” ë…¼ë¬¸

  **SmartBrush: Text and Shape Guided Object Inpainting with Diffusion Model**\
  *Shaoan Xie, Zhifei Zhang, Zhe Lin, Tobias Hinz, Kun Zhang*\
  arXiv 2022. [[Paper](https://arxiv.org/abs/2212.05034)]\
  [Submitted on 9 Dec 2022]\
  ë§ˆìŠ¤í¬ë¥¼ ì£¼ë©´ ê±°ê¸°ì— í…ìŠ¤íŠ¸ì— í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€ ìƒì„±. ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ë¸ì„ í›ˆë ¨ì„ ì‹œí‚¤ëŠ”ë°, ë§ˆìŠ¤í¬ì— ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ì»¤ë„ì„ í†µê³¼ì‹œí‚¤ê³ , ìƒì„±ë˜ëŠ” ì´ë¯¸ì§€ì—ì„œ ë§ˆìŠ¤í¬ë¥¼ predict í•˜ê²Œ í•˜ì—¬ predictëœ ë§ˆìŠ¤í¬ ì˜ì—­ë§Œ ëŒ€ì²´í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ backgroundë¥¼ ìµœëŒ€í•œ ì§€í‚¨ë‹¤. ì‹¤ì œë¡œ ìƒì„± ì˜ì—­ì„ ë„“ê²Œ ì¡ì•„ë„ backgroundê°€ ìƒë‹¹íˆ ì˜ ìœ ì§€ëœë‹¤.


## Image Generation

**On the Importance of Noise Scheduling for Diffusion Models** \
*Ting Chen* \
arXiv 2023. [[Paper](https://arxiv.org/abs/2301.10972)]\
high resolution ì—ì„œëŠ” ê°™ì€ SNR ì—ì„œë„ ì´ë¯¸ì§€ê°€ ëœ ë§ê°€ì§€ëŠ” ê²ƒìœ¼ë¡œë¶€í„°, resolution ë³„ ìƒˆë¡œìš´ noise scheduling ì„ ì œì•ˆí•¨. \
ì´ë¯¸ì§€ê°€ í´ìˆ˜ë¡ ì •ë³´ê°€ ì‚´ì•„ë‚¨ëŠ” ê²ƒìœ¼ë¡œë¶€í„° ì°©ì•ˆí•˜ì—¬, signal ì„ ë‚®ì¶°ì£¼ëŠ” $xt=\sqrt{\alpha} b x_0 + \sqrt{1 - \alpha} \epsilon ì„ ì œì•ˆ.\
+) UNet backbone ì´ ì•„ë‹™ë‹ˆë‹¤.

**eDiff-I: Text-to-Image Diffusion Models with an Ensemble of Expert Denoisers** \
*Yogesh Balaji, Seungjun Nah, Xun Huang, Arash Vahdat, Jiaming Song, Karsten Kreis, Miika Aittala, Timo Aila, Samuli Laine, Bryan Catanzaro, Tero Karras, Ming-Yu Liu*\
arxiv [Submitted on 2 Nov 2022 (v1), last revised 17 Nov 2022 (this version, v4)]\
 Nvidia version large text-to-image model, í•œê°œì˜ diffusion modelë§ê³  ê° stpeë³„ë¡œ ì—¬ëŸ¬ê°œì˜ networkë¥¼ í•™ìŠµì‹œì¼œ ensembleí•œë‹¤.

**Score-Based Generative Modeling with Critically-Damped Langevin Diffusion** \
*Tim Dockhorn, Arash Vahdat, Karsten Kreis* \
arXiv 2021. [[Paper](https://arxiv.org/abs/2112.07068)] [[Project](https://nv-tlabs.github.io/CLD-SGM/)] \
14 Dec 2021 \
Nvidiaì—ì„œ ë‚¸ ë…¼ë¬¸ìœ¼ë¡œ ê¸°ì¡´ì— Score-basedì— velocity ì¶•ì„ í•˜ë‚˜ ë” ë§Œë“¤ì–´ì„œ ìˆ˜ë ´ë„ ì˜ ë˜ê³  í•™ìŠµë„ ë¹ ë¥´ê²Œ ë§Œë“¬. ìˆ˜í•™ì ìœ¼ë¡œ ì˜ ì •ë¦¬ë˜ì–´ìˆì–´ì„œ ì¢‹ì€ ë…¼ë¬¸.

**Cascaded Diffusion Models for High Fidelity Image Generation** \
*Jonathan Ho<sup>1</sup>, Chitwan Saharia<sup>1</sup>, William Chan, David J. Fleet, Mohammad Norouzi, Tim Salimans* \
arXiv 2021. [[Paper](https://arxiv.org/abs/2106.15282)] [[Project](https://cascaded-diffusion.github.io/)] \
30 May 2021 \
ì´ë¯¸ì§€ resolutionì„ í‚¤ì›Œê°€ë©´ì„œ ìƒì„±í•˜ëŠ” ë°©ë²• ì†Œê°œ.

**Soft Truncation: A Universal Training Technique of Score-based Diffusion Model for High Precision Score Estimation**\
*Dongjun Kim, Seungjae Shin, Kyungwoo Song, Wanmo Kang, Il-Chul Moon*\
icml 2022. [[Paper](https://arxiv.org/abs/2106.05527)] \
11 Jun 2022 \
ì´ë¯¸ì§€ë¥¼ ì¢€ ë” ì˜ ë½‘ì•„ë‚´ëŠ” ë°©ë²• ì†Œê°œ.

**Your ViT is Secretly a Hybrid Discriminative-Generative Diffusion Model** \
*Xiulong Yang<sup>1</sup>, Sheng-Min Shih<sup>1</sup>, Yinlin Fu, Xiaoting Zhao, Shihao Ji* \
arXiv 2022. [[Paper](https://arxiv.org/abs/2208.07791)] [[Github](https://github.com/sndnyang/Diffusion_ViT)] \
16 Aug 2022 \
ViTë¥¼ ê°€ì§€ê³  Diffusionì„ ë§Œë“¤ì—ˆì§€ë§Œ classificationë„ ê°™ì´ í•œë‹¤ëŠ” ê²ƒì´ ì¤‘ìš”í¬ì¸íŠ¸. ê·¸ëŸ¬ë‚˜ ì´ë¯¸ì§€ ìƒì„± ì„±ëŠ¥ì€ ê·¸ë¦¬ ì¢‹ì§€ ëª»í•¨. ë‹¤ë§Œ ê¸°ì¡´ í•˜ì´ë¸Œë¦¬ë“œëª¨ë¸ ì¤‘ì—ì„  ì œì¼ ì¢‹ì€ë“¯.

**Progressive Deblurring of Diffusion Models for Coarse-to-Fine Image Synthesis, Sangyun Lee et al., 2022** \
*Sangyun Lee, Hyungjin Chung, Jaehyeon Kim, Jong Chul Ye* \
arXiv 2022. [[Paper](https://arxiv.org/abs/2207.11192?context=cs)] [[Project](https://github.com/sangyun884/blur-diffusion)] \
16 Jul 2022 \
ìƒìœ¤ì¢Œì˜ ë…¼ë¬¸ìœ¼ë¡œ, diffusion modelsì˜ generationê³¼ì •ì´ coarse-to-fineì´ ì•„ë‹ˆë¼ holistically ìƒì„±ë˜ëŠ”ê²ƒì— ì£¼ëª©í•˜ì—¬ ì´ë¥¼ í•´ê²°í•˜ê³ ì blur kernelì„ ì‚½ì…í•˜ì—¬ train.
Noiseì— ê°€ê¹Œìš¸ ìˆ˜ë¡ low frequency ì •ë³´ë§Œ ë‚¨ë„ë¡ gaussian kernel í†µê³¼ì‹œí‚¤ê³ , ê²°ê³¼ì ìœ¼ë¡œ low freqeucny(content)ì •ë³´ë¶€í„° ë¯¸ë¦¬ ìƒì„±í•˜ê³ , high freqeuncy(style, detail)ì„ ë‚˜ì¤‘ì— ìƒì„±í•˜ë„ë¡ explicit biasë¥¼ ì¤Œ.

**Soft Diffusion: Score Matching for General Corruptions, Giannis Daras et al., 2022**  \
*Giannis Daras, Mauricio Delbracio, Hossein Talebi, Alexandros G. Dimakis, Peyman Milanfar* \
arXiv 2022. [[Paper](https://arxiv.org/abs/2209.05442)] \
12 Sep 2022 \
gaussian noiseë§ê³  blurê¹Œì§€ ì”Œìš°ë©´ fidê°€ ë” ì¢‹ì•„ì§„ë‹¤ + new sampling method (momentum sampling)ì œì•ˆ, noise(blur) scheduling ì œì•ˆ\

**Maximum Likelihood Training of Implicit Nonlinear Diffusion Models**\
*Dongjun Kim, Byeonghu Na, Se Jung Kwon, Dongsoo Lee, Wanmo Kang, Il-Chul Moon*\
NeurIPS22. [[Paper](https://arxiv.org/abs/2205.13699)]\
27 May 2022 \
Normalizing flowì˜ invertibleí•œ ì„±ì§ˆì„ ì ìš©í•˜ì—¬, data adatible í•œ nonlinear diffusion processë¥¼ implicití•˜ê²Œ í•™ìŠµ. FID ì„±ëŠ¥ì„ ì˜¬ë¦¼.\

**Scalable Diffusion Models with Transformers** \
*William Peebles, Saining Xie* \
arXiv 2022. [[Paper](https://arxiv.org/abs/2212.09748)] [[Project page](https://www.wpeebles.com/DiT)] [[Git](https://github.com/facebookresearch/DiT)]\
[Submitted on 19 Dec 2022] \
íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ì‚¬ìš©í•´ì„œ ì´ë¯¸ì§€ë„·ì—ì„œ SOTA. ê¸°ë³¸ì ìœ¼ë¡œ VAEì˜ latent ìƒì—ì„œì˜ Diffusionì´ë©°, të‘ classë¥¼ concat í•´ì„œ mlp í•˜ë‚˜ íƒœìš°ê³ , adaLN ì„ ì ìš©ì‹œí‚´. ì•½ê°„ LDMì„ transformerë¡œ êµ¬í˜„í•œ ëŠë‚Œ. ì‹¤í—˜ ì¢‹ê³  ë‚´ìš© ê°„ë‹¨í•œë° êµ³ì´ ì—´ì‹¬íˆ ì½ì–´ë³¼ í•„ìš”ëŠ” ì—†ëŠ” ë…¼ë¬¸. \
  
**On the Importance of Noise Scheduling for Diffusion Models** \
*Ting Chen* \
arXiv 2023. [[Paper](https://arxiv.org/abs/2301.10972)]\
high resolution ì—ì„œëŠ” ê°™ì€ SNR ì—ì„œë„ ì´ë¯¸ì§€ê°€ ëœ ë§ê°€ì§€ëŠ” ê²ƒìœ¼ë¡œë¶€í„°, resolution ë³„ ìƒˆë¡œìš´ noise scheduling ì„ ì œì•ˆí•¨. \
ì´ë¯¸ì§€ê°€ í´ìˆ˜ë¡ ì •ë³´ê°€ ì‚´ì•„ë‚¨ëŠ” ê²ƒìœ¼ë¡œë¶€í„° ì°©ì•ˆí•˜ì—¬, signal ì„ ë‚®ì¶°ì£¼ëŠ” $xt=\sqrt{\alpha} b x_0 + \sqrt{1 - \alpha} \epsilon ì„ ì œì•ˆ.\
+) UNet backbone ì´ ì•„ë‹™ë‹ˆë‹¤.
  


## Connection with other framworks

**Diffusion Autoencoders: Toward a Meaningful and Decodable Representation** \
*Konpat Preechakul, Nattanat Chatthee, Suttisak Wizadwongsa, Supasorn Suwajanakorn* \
CVPR 2022. [[Paper](https://arxiv.org/abs/2111.15640)] [[Project](https://diff-ae.github.io/)] [[Github](https://github.com/phizaz/diffae)] \
30 Dec 2021 \
Diffusion modelsì— semantic latentë¥¼ ì»¨ë””ì…˜ìœ¼ë¡œ ì£¼ì–´ì„œ Autoencoder ì²˜ëŸ¼ ë§Œë“¬. ê·¸ë˜ì„œ latentê°€ ìƒê²¼ê³ , manipulationì´ ê°€ëŠ¥í•´ì§. ì„±ëŠ¥ ì¢‹ê³  ì˜ë¨.

**DiffuseVAE: Efficient, Controllable and High-Fidelity Generation from Low-Dimensional Latents** \
*Kushagra Pandey, Avideep Mukherjee, Piyush Rai, Abhishek Kumar* \
arXiv 2022. [[Paper](https://arxiv.org/abs/2201.00308)] [[Github](https://github.com/kpandey008/DiffuseVAE)] \
2 Jan 2022 \
ì œëŒ€ë¡œ ëª»ì½ì—ˆì§€ë§Œ, VAEì˜ í˜•íƒœë¥¼ ë¹Œë ¤ì™€ì„œ í•©ì¹œ ë…¼ë¬¸.

**High-Resolution Image Synthesis with Latent Diffusion Models** \
*Robin Rombach<sup>1</sup>, Andreas Blattmann<sup>1</sup>, Dominik Lorenz, Patrick Esser, BjÃ¶rn Ommer* \
arXiv 2021. [[Paper](https://arxiv.org/abs/2112.10752)] [[Github](https://github.com/CompVis/latent-diffusion)] \
20 Dec 2021 \
global AutoEncoderë¥¼ í•™ìŠµí•´ì„œ ê·¸ latent ìƒì—ì„œ diffusionì„ í•œ ë…¼ë¬¸. stable-diffusionì´ ì´ ë…¼ë¬¸ì´ë‹¤.

**Score-based Generative Modeling in Latent Space** \
*Arash Vahdat<sup>1</sup>, Karsten Kreis<sup>1</sup>, Jan Kautz* \
arXiv 2021. [[Paper](https://arxiv.org/abs/2106.05931)] \
10 Jun 2021
VAEë‘ í•©ì¹œ ë…¼ë¬¸. VAEì™€ Diffusionì„ ë™ì‹œì— í•™ìŠµ. Diffusionì€ VAEì˜ latent spaceì—ì„œ í•™ìŠµëœë‹¤.

**Tackling the Generative Learning Trilemma with Denoising Diffusion GANs** \
*Zhisheng Xiao, Karsten Kreis, Arash Vahdat* \
ICLR 2022 (Spotlight). [[Paper](https://arxiv.org/abs/2112.07804)] [[Project](https://nvlabs.github.io/denoising-diffusion-gan)] \
15 Dec 2021 \
GANìœ¼ë¡œ íŠ¹ì • timestepì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ ìƒ˜í”Œë§ë„ ë¹ ë¥´ê²Œ, í€„ë¦¬í‹°ë„ ì¢‹ê²Œ í•¨. GAN+Diffusion.

## Image space guidance sampling

**ILVR: Conditioning Method for Denoising Diffusion Probabilistic Models** \
*Jooyoung Choi, Sungwon Kim, Yonghyun Jeong, Youngjune Gwon, Sungroh Yoon* \
ICCV 2021 (Oral). [[Paper](https://arxiv.org/abs/2108.02938)] [[Github](https://github.com/jychoi118/ilvr_adm)] \
6 Aug 2021 \
ì´ë¯¸ì§€ë¥¼ Low-pass filter í†µê³¼ì‹œí‚¨ í›„ í•©ì³ì„œ ì›í•˜ëŠ” ì´ë¯¸ì§€ë‘ ë¹„ìŠ·í•œ ì´ë¯¸ì§€ ìƒì„±

**RePaint: Inpainting using Denoising Diffusion Probabilistic Models** \
*Andreas Lugmayr, Martin Danelljan, Andres Romero, Fisher Yu, Radu Timofte, Luc Van Gool* \
CVPR 2022. [[Paper](https://arxiv.org/abs/2201.09865)] [[Github](https://github.com/andreas128/RePaint)] \
24 Jan 2022 \
Inpainting ë…¼ë¬¸. ë§ˆìŠ¤í¬ëœ ì˜ì—­ë§Œ ë°”ê¿”ê»´ì£¼ëŠ” ë°©ì‹ì„ ì œì•ˆ. ì—¬ëŸ¬ë²ˆ ëŒë¦¬ëŠ” ë°©ë²•ë§Œ ì£¼ëª©í•´ì„œ ë³´ë©´ ë¨. ë‚˜ë¨¸ì§„ ê·¸ë‹¥ í•„ìš” ì—†ìŒ.

**SDEdit: Image Synthesis and Editing with Stochastic Differential Equations**  \
*Chenlin Meng, Yang Song, Jiaming Song, Jiajun Wu, Jun-Yan Zhu, Stefano Ermon* \
ICLR 2022. [[Paper](https://arxiv.org/abs/2108.01073)] [[Project](https://sde-image-editing.github.io/)] [[Github](https://github.com/ermongroup/SDEdit)] \
2 Aug 2021 \
strokeë¥¼ ë…¸ì´ì¦ˆë¥¼ ì ë‹¹íˆ ì”Œì› ë‹¤ê°€ ìƒ˜í”Œë§í•˜ë©´ ë¹„ìŠ·í•œ ìƒ‰ì˜ realí•œ ì´ë¯¸ì§€ë¥¼ ì–»ì„ ìˆ˜ ìˆìŒ.

## Classifier guidance sampling

**Blended Diffusion for Text-driven Editing of Natural Images** \
*Omri Avrahami, Dani Lischinski, Ohad Fried* \
CVPR 2022. [[Paper](https://arxiv.org/abs/2111.14818)] [[Project](https://omriavrahami.com/blended-diffusion-page/)] [[Github](https://github.com/omriav/blended-diffusion)] \
29 Nov 2021 \
íŠ¹ì • ì˜ì—­ì—ë§Œ CLIPì„ ê°€ì§€ê³  classifier guidanceë¡œ text promptì— ë§ê²Œ ì´ë¯¸ì§€ ìƒì„±.

**More Control for Free! Image Synthesis with Semantic Diffusion Guidance** \
*Xihui Liu, Dong Huk Park, Samaneh Azadi, Gong Zhang, Arman Chopikyan, Yuxiao Hu, Humphrey Shi, Anna Rohrbach, Trevor Darrell* \
arXiv 2021. [[Paper](https://arxiv.org/abs/2112.05744)] [[Github](https://xh-liu.github.io/sdg/)] \
10 Dec 2021 \
ì²˜ìŒìœ¼ë¡œ textì™€ image guidanceë¥¼ ë‘˜ ë‹¤ ì¤„ ìˆ˜ ìˆë‹¤ê³  ì„¤ëª…í•˜ëŠ” ë…¼ë¬¸. ê·¸ëŸ°ë° ë‘˜ ë‹¤ CLIPì„ ì‚¬ìš©í•œ classifier guidanceì´ë‹¤.

**Generating High Fidelity Data from Low-density Regions using Diffusion Models** \
*Vikash Sehwag, Caner Hazirbas, Albert Gordo, Firat Ozgenel, Cristian Canton Ferrer* \
CVPR2022, arXiv 2022. [[Paper](https://arxiv.org/abs/2203.17260)] \
31 Mar 2022 \
GANì²˜ëŸ¼ Discriminatorë¥¼ í•˜ë‚˜ ì‚¬ìš©í•´ì„œ í™•ë¥ ì´ ë‚®ì€ ì´ë¯¸ì§€ë¥¼ ë½‘ë„ë¡ ìœ ë„. Low-density ì´ë¯¸ì§€ë¥¼ ìƒì„±í•¨.

**Self-Guided DIffusion Models** \
*Vincent Tao Hu, David W.Zhang, Yuki M.Asano, Gertjan J. Burghouts, Cees G. M. Snoek* \
arXiv 2022. [[Paper](https://arxiv.org/abs/2210.06462)] \
12 Oct 2022 \
Off-the-shelf modelë“¤ì˜ ì‚¬ìš©ìœ¼ë¡œ featureë¥¼ ë½‘ì•„ë‚´ê³  í´ëŸ¬ìŠ¤í„°ë§ì„ í™œìš©í•œ self-guided label -> classifier, object detection, semantic segmentation ë“±ìœ¼ë¡œ guidanceë¥¼ ì£¼ì–´ ê·¸ì— ë”°ë¥´ ì´ë¯¸ì§€ìƒì„± (ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ë“¯, high resolution ì–´ë µë‹¤ëŠ” ë‹¨ì )

## Image Editing

 **Zero-Shot Image Restoration Using Denoising Diffusion Null-Space Model**\
  *Yinhuai Wang, Jiwen Yu, Jian Zhang*\
  arXiv 2022. [[Paper](https://arxiv.org/abs/2212.00490)] \
  Linear Degradation $\mathbf{A}$ ë¥¼ ì•Œê³  ìˆì„ë•Œ, Realness restoration ì„ $\mathbf{A}$ ì˜ null-space ì—ì„œë§Œ ì§„í–‰í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆ. ì‹¤ì§ˆì ì¸ ì´ë¯¸ì§€ í€„ë¦¬í‹° í–¥ìƒì€ Repaint ì—ì„œ ì œì•ˆëœ time-travel ê¸°ë²•ì„ í†µí•´ ì´ë¤„ì¡Œë‹¤. 

**Zero-shot Image-to-Image Translation**\
*Gaurav Parmar, Krishna Kumar Singh, Richard Zhang, Yijun Li, Jingwan Lu, Jun-Yan Zhu*\
arXiv 2023. [[Paper](https://arxiv.org/abs/2302.03027)] \
6 Feb 2022 \
ë³„ë„ì˜ user prompt ì—†ì´ source word(eg. dog) ì™€ target word(e.g. cat) ë§Œ ê°€ì§€ê³  image translationí•˜ëŠ” ë…¼ë¬¸. í•´ë‹¹ ë‹¨ì–´ê°€ í¬í•¨ëœ ì—¬ëŸ¬ê°œì˜ ë¬¸ì¥ì˜ CLIP embedding ê°„ì˜ ì°¨ì´ë¥¼ editing directionìœ¼ë¡œ ì„¤ì •í•˜ì—¬ inference í• ë•Œ text conditionì— directionë§Œ ë”í•˜ì—¬ editing ê°€ëŠ¥, input imageì˜ content structure ìœ ì§€ë¥¼ ìœ„í•´ì„œ cross attention guidanceë¥¼ ì œì‹œ(contentì™€ backgroundìœ ì§€ êµ¿), gaussian distributionìœ ì§€ë¥¼ ìœ„í•œ autocorrelation regularization ì œì•ˆ. 

**Null-text Inversion for Editing Real Images using Guided Diffusion Models** \
*Ron Mokady, Amir Hertz, Kfir Aberman, Yael Pritch, Daniel Cohen-Or* \
arXiv 2022. [[Paper](https://arxiv.org/abs/2211.09794)] \
17 Nov 2022 \
ë³„ë„ì˜ model fine-tuning ì—†ì´, real image ì— í•´ë‹¹í•˜ëŠ” null-textë¥¼ optimization í•˜ì—¬ prompt2prompt ë°©ì‹ìœ¼ë¡œ objectì˜ semantic detailì„ ìœ ì§€í•˜ë©´ì„œ image editingì„ ê°€ëŠ¥í•˜ê²Œí•¨. ë°©ë²• ì¢‹ì€ ê²°ê³¼ ì¢‹ì€. ê´œì°®ì€ ë…¼ë¬¸.

**Paint by Example: Exemplar-based Image Editing with Diffusion Models** \
*Binxin Yang, Shuyang Gu, Bo Zhang, Ting Zhang, Xuejin Chen, Xiaoyan Sun, Dong Chen, Fang Wen* \
CVPR2023 submission. [[Paper](https://arxiv.org/abs/2211.13227)] \
[Submitted on 23 Nov 2022] \
ìœ ì €ê°€ ì§€ì •í•œ ì˜ì—­ì— ì»¨ë””ì…˜ìœ¼ë¡œ ì£¼ì–´ì§„ ì´ë¯¸ì§€ì˜ semanticì„ ìƒì„±í•œ ë…¼ë¬¸. 1. StableDiffusionìœ¼ë¡œ init 2. ì´ë¯¸ì§€ì˜ ë©”ì¸ ì˜¤ë¸Œì íŠ¸ íŒ¨ì¹˜ë¥¼ ë–¼ì–´ë‚´ê³ , CLIP ì´ë¯¸ì§€ ì¸ì½”ë”ì— augmentationí•´ì„œ ë„£ì–´ì¤€ë‹¤. ì´ ë•Œ CLIPì„ 1024ê¹Œì§€ ì„ë² ë”©ì„ ì‹œì¼œë²„ë¦¬ê³ , ì´ê±¸ ë‹¤ì‹œ ë¦¬ë‹ˆì–´ë ˆì´ì–´ ëª‡ê°œ í†µê³¼ì‹œì¼œì„œ ì»¨ë””ì…˜ìœ¼ë¡œ ë„£ì–´ì¤Œ. 3. 2ë²ˆì— ë”°ë¼ì„œ í•™ìŠµ.  ê²°ê³¼ ì¢‹ìŒ. ë°©ë²• ì¢‹ìŒ. ë…¼ë¬¸ ì˜ ì½í˜. ê´œì°®ì€ ë…¼ë¬¸.

**Denoising Diffusion Restoration Models** \
*Bahjat Kawar, Michael Elad, Stefano Ermon, Jiaming Song* \
arXiv 2022. [[Paper](https://arxiv.org/abs/2201.11793)] \
27 Jan 2022 \
ì´ë¯¸ì§€ ìì²´ê°€ í•˜ìê°€ ìˆë‹¤ê³  ìƒê°í•˜ê³  íŠ¹ì • í–‰ë ¬ ê³±ìœ¼ë¡œ ë…¸ì´ì¦ˆë‚˜.. í¬ë¡­ì´ë‚˜.. ê·¸ëŸ°ê±¸ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë‹¤ë©´ ì›ë³¸ì„ ë³µêµ¬í•˜ëŠ” ë°©ì‹ ì œì•ˆ.

**Palette: Image-to-Image Diffusion Models** \
*Chitwan Saharia, William Chan, Huiwen Chang, Chris A. Lee, Jonathan Ho, Tim Salimans, David J. Fleet, Mohammad Norouzi* \
NeurlPS 2022. [[Paper](https://arxiv.org/abs/2111.05826)] \
10 Nov 2021 \
ë³„ê±° ì•ˆí•˜ê³  ê·¸ëƒ¥ íŠœë‹í•´ì„œ ëª¨ë¸ í•˜ë‚˜ë¡œ 4ê°€ì§€ taskì—ì„œ SOTA ë‹¬ì„±.

**DiffEdit: Diffusion-based semantic image editing with mask guidance** \
*Guillaume Couairon, Jakob Verbeek, Holger Schwenk, Matthieu Cord* \
Submitted to ICLR2023. [[Paper](https://arxiv.org/abs/2210.11427)] \
20 Oct 2022 \
Reference textì™€ query textê°€ ì£¼ì–´ì¡Œì„ë•Œ ë‘ í…ìŠ¤íŠ¸ë¥¼ ì ìš©í–ˆì„ë•Œì˜ noise estimates ì°¨ì´ë¡œ ë§ˆìŠ¤í¬ë¥¼ ìƒì„± - ìƒì„±í•œ ë§ˆìŠ¤í¬ë¥¼ í†µí•´ DDIM decodingê³¼ì •ì—ì„œ encodingëœ ê²ƒê³¼ ì ì ˆíˆ í•©ì³ì„œ text ë¶€ë¶„ë§Œ edití•˜ëŠ” ê°„ë‹¨í•œ ë°©ë²•.

**DiffusionCLIP: Text-guided Image Manipulation Using Diffusion Models** \
*Gwanghyun Kim, Jong Chul Ye* \
CVPR 2022. [[Paper](https://arxiv.org/abs/2110.02711)] \
6 Oct 2021 \
CLIPì„ ê°€ì§€ê³  modelì„ finetuningí•´ì„œ ì›í•˜ëŠ” attributeë¡œ ë³€í™˜í•˜ëŠ” ë…¼ë¬¸.

**TEXT-GUIDED DIFFUSION IMAGE STYLE TRANSFER WITH CONTRASTIVE LOSS FINE-TUNING** \
*Anonymous authors* \
Submitted to ICLR2023. [[Paper](https://openreview.net/forum?id=iJ_E0ZCy8fi)] \
30 Sept 2022 \
CLIP (global + directional) & CUT loss (UNet featuremapë“¤ì„ íŒ¨ì¹˜ë¡œ ìª¼ê°œì„œ contrastive loss)ë¥¼ ì‚¬ìš©í•´ì„œ stylestransfer.

**Plug-and-Play Diffusion Features for Text-Driven Image-to-Image Translation** \
*Narek Tumanyan, Michal Geyer, Shai Bagon, Tali Dekel* \
CVPR 2023 Submission / preprint [[Paper](https://arxiv.org/abs/2211.12572)] [[Project page](https://pnp-diffusion.github.io)] \
[Submitted on 22 Nov 2022]
Stable Diffusionì˜ 4th layerì˜ featuremapê³¼ 4-11th laeyrì˜ self attention Q,K ê°’ì„ injection í•˜ì—¬ real imageì˜ structureë¥¼ ìœ ì§€í•˜ë©´ì„œ text guidedë¡œ I2I translationì„ ê°€ëŠ¥í•˜ê²Œ í•¨. Diffusion modelì€ freeze, featureë§Œ ë§Œì ¸ì„œ ì„±ê³µì ìœ¼ë¡œ editing. ì¢‹ì€ ì ‘ê·¼.

**Diffusion Models already have a Semantic Latent Space** \
*Mingi Kwon, Jaeseok Jeong, Youngjung Uh* \
ICLR 2023 Submission / preprint [[Paper](https://arxiv.org/abs/2210.10960)] [[Project page](https://kwonminki.github.io/Asyrp/)] \
[Submitted on 20 Oct 2022] \
DDIMì˜ ìƒ˜í”Œë§ ê³µì‹ ì¤‘ predicted x0 ë¶€ë¶„ë§Œ ë°”ê¿”ì£¼ë©´ U-Netì˜ bottle-neck ë¶€ë¶„ì„ semantic latent spaceë¡œ ì“¸ ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤€ ë…¼ë¬¸. Asyrpì„ ì œì•ˆí•¨. ì˜ë©ë‹ˆë‹¹ ì¢‹ì€ ë…¼ë¬¸ì…ë‹ˆë‹¹ ì½ì–´ì£¼ì„¸ìš”.

**EDICT: Exact Diffusion Inversion via Coupled Transformations** \
*Bram Wallace, Akash Gokul, Nikhil Naik* \
arXiv 2022. [[Paper](https://arxiv.org/abs/2211.12446)]\
DDIM inversion ê³¼ Normalizing flow ì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” Affine coupling layer ì˜ ìˆ˜ì‹ì´ ë™ì¼í•˜ë‹¤ëŠ” ì ì—ì„œ ì°©ì•ˆí•˜ì—¬, ì™„ë²½í•˜ê²Œ inversion ë˜ëŠ” process ë¥¼ ì œì•ˆ. \
text-conditional ì¼ë•Œë‚˜ guidance scale ì´ í´ë•Œë„ reconstruction ì„±ëŠ¥ì´ ì¢‹ìŠµë‹ˆë‹¤.

  **Boundary Guided Mixing Trajectory for Semantic Control with Diffusion Models**\
  *Ye Zhu, Yu Wu, Zhiwei Deng, Olga Russakovsky, Yan Yan*\
  arXiv 2023. [[Paper](https://arxiv.org/abs/2212.05034)]\
  [Submitted on 16 Feb 2023]\
  Asyrpì„ ì‚¬ìš©í•˜ë©´ (Diffusion models already have a semantic latent space) ìƒê¸°ëŠ” ë¬¸ì œë¥¼ inversion ì´ë¯¸ì§€ì™€ generated ì´ë¯¸ì§€ì˜ xT ë¶„í¬ë¥¼ ê°€ì§€ê³  ë¶„ì„í•¨. inversioní•œ ì´ë¯¸ì§€ê°€ ê°€ìš°ì‹œì•ˆ ë¶„í¬ ê»ì§ˆ ì•ˆìª½ì— ìˆë‹¤ê³  ë§í•˜ê³ , ì´ê±¸ ë§ì¶°ì£¼ëŠ” ë°©ì‹ì„ ì œì•ˆí•¨. - ì œëŒ€ë¡œ ì•ˆì½ì–´ì„œ ì¶”í›„ ì—…ë°ì´íŠ¸ ì˜ˆì •.
  

## Text-focused

**Multi-Concept Customization of Text-to-Image Diffusion** \
*Nupur Kumari, Bingliang Zhang, Richard Zhang, Eli Shechtman, Jun-Yan Zhu* \
arxiv Submitted on 8 Dec 2022 \ 
preprint [[Paper](https://arxiv.org/abs/2212.04488)] \
 1)model ì¼ë¶€ë§Œ fine-tuning + 2) text optimization ì„ í†µí•´ì„œ Large text-to-image Diffusion modelì„ few-shot user images ìƒì—ì„œ customizing í•˜ëŠ” ë…¼ë¬¸

**Optimizing Prompts for Text-to-Image Generation** \
*Yaru Hao, Zewen Chi, Li Dong, Furu Wei* \
arXiv 2022. [[Paper](https://arxiv.org/abs/2212.09611)][[Demo page](https://huggingface.co/spaces/microsoft/Promptist)][[Git](https://github.com/microsoft/LMOps/tree/main/promptist)] \
[Submitted on 19 Dec 2022] \
"A white knight riding a black horse." -> "a white knight riding a black horse, intricate, elegant, highly detailed, digital painting, artstation, concept art, sharp focus, illustration, by justin gerard and artgerm, 8 k" í…ìŠ¤íŠ¸ ë’¤ì— ë¶™ëŠ” ê¸€ìë“¤ì„ ê°•í™”í•™ìŠµìœ¼ë¡œ ë§Œë“¤ì–´ë‚¸ë‹¤. GPTëª¨ë¸ì„ prompt pairë¡œ fintuningí•˜ì—¬ policy ëª¨ë¸ë¡œ ì‚¬ìš©í•œë‹¤. ì´ë¯¸ì§€ì˜ ì‹¬ë¯¸ì , í…ìŠ¤íŠ¸ ë°˜ì˜ì„ ê¸°ë°˜ìœ¼ë¡œ rewardë¥¼ ì£¼ëŠ” í˜•íƒœë¡œ ì§œì—¬ì ¸ ìˆë‹¤.

**An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion** \
*Rinon Gal, Yuval Alaluf, Yuval Atzmon, Or Patashnik, Amit H. Bermano, Gal Chechik, Daniel Cohen-Or* \
arXiv 2022. ICLR2023 submission [[Paper](https://arxiv.org/abs/2208.01618)] \
[Submitted on 2 Aug 2022] \
ì´ë¯¸ì§€ 3~5ì¥ì„ S* ë¼ëŠ” ë¬¸ìë¡œ inversioní•œë‹¤. GAN inversionê³¼ ìœ ì‚¬. ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ê³¼ì •ì—ì„œ ë‚˜ì˜¤ëŠ” ë…¸ì´ì¦ˆì™€ given imageë¥¼ inversion í•˜ëŠ” ê³¼ì •ì—ì„œ ë‚˜ì˜¤ëŠ” ë…¸ì´ì¦ˆê°„ì˜ MSE lossë¥¼ ì‚¬ìš©í•˜ì—¬ "A photo of S*" ë¼ëŠ” promptì˜ S*ì— í•´ë‹¹í•˜ëŠ” í† í°ì„ ì§ì ‘ optimizeí•œë‹¤.


## Fast Sampling

**Progressive Distillation for Fast Sampling of Diffusion Models**\
  *Tim Salimans, Jonathan Ho*\
  arXiv 2022. [[Paper](https://arxiv.org/abs/2202.00512)] \
  Faster sampling ì„ ëª©í‘œë¡œ, denoising 2 step ì„ ì˜ˆì¸¡í•˜ëŠ” student ëª¨ë¸ì„ í•™ìŠµì‹œí‚¨ë‹¤. ì´ë•Œ, $\epsilon$-prediction ì„ í•˜ê²Œ ë  ê²½ìš° ê¸°ì¡´ê³¼ëŠ” ë‹¬ë¦¬ numerical error ì— ëŒ€í•œ correction ì´ ì´ë¤„ì§ˆ ìˆ˜ ì—†ì–´ì„œ v-prediction ì´ë¼ëŠ” ìƒˆë¡œìš´ parameterization ì„ ì œì•ˆí•¨. (v-prediction ì€ ìƒê°ë³´ë‹¤ ìì£¼ ì“°ì´ë‹ˆ Appendix D ëŠ” ë³´ê¸°ë¥¼ ì¶”ì²œ)
  
**On distillation of guided diffusion models** \
*Chenlin Meng, Robin Rombach, Ruiqi Gao, Diederik P. Kingma, Stefano Ermon, Jonathan Ho, Tim Salimans* \
arXiv 2022. [[Paper](https://arxiv.org/abs/2210.03142)]\
ë‘ë²ˆì˜ distillation ìœ¼ë¡œ step ì„ 1~4 step ìœ¼ë¡œ ë¹„ì•½ì ìœ¼ë¡œ ì¤„ì¸ë‹¤. LDM ì˜ ê²½ìš° 1 step ê¹Œì§€ ê°€ëŠ¥í•˜ë‹¤. \
stage 1. classifier-free guidance ì˜ score ì— ëŒ€í•œ student ëª¨ë¸ í•™ìŠµ. \
stage 2. progressive-distillation ì„ í†µí•´ step ìˆ˜ë¥¼ N/2 ìœ¼ë¡œ ê³„ì† ì¤„ì—¬ë‚˜ê°.

**Minimizing Trajectory Curvature of ODE-based Generative Models** \
*Sangyun Lee, Beomsu Kim, Jong Chul Ye*\
arxiv 27 Jan 2023 [[Paper] (https://arxiv.org/abs/2301.12003)]\
sampling trajectoryì˜ curvatureë¥¼ ì¤„ì—¬ì„œ í•™ìŠµëœ denoising modelì— ode solver ê°€ fit í•˜ë„ë¡ ë§Œë“¤ê³ , ì ì€ stepì—ì„œë„ generation, reconstructionì´ ì˜ ë˜ë„ë¡ ì‹œë„í•¨

**Learning Fast Samplers for Diffusion Models by Differentiating Through Sample Quality** \
*Daniel Watson, William Chan, Jonathan Ho, Mohammad Norouzi* \
ICLR 2022. [[Paper](https://openreview.net/forum?id=VFBjuF8HEp)]  \
11 Feb 2022 \
Pre-trainedì„ fine-tunning í•˜ì§€ ì•Šê³  step#ë¥¼ ì¤„ì—¬ì„œ ë¹ ë¥´ê²Œ sampling í•˜ë©´ì„œë„ FID/IS ë¥¼ ìµœëŒ€í•œ ìœ ì§€í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì œì‹œ,
diffusionì˜ object function(ELBO) termì„ ë¬´ì‹œí•˜ê³ , stepê³¼ stepì‚¬ì´ì— samplingí•˜ëŠ” paremeterë“¤ë§Œ KID loss ë¥¼ ì¤˜ì„œ train.

**Pseudo Numerical Methods for Diffusion Models on Manifolds** \
*Luping Liu, Yi Ren, Zhijie Lin, Zhou Zhao* \
ICLR 2022 Poster [[Paper](https://arxiv.org/abs/2202.09778)] \
Submitted on 20 Feb 2022  \
ì´ì „ numerical ODEì˜ ë°©ì‹ì´ DDPMì˜ sampling manifoldë¥¼ ì œëŒ€ë¡œ ë°˜ì˜í•˜ì§€ ëª»í•¨ì„ ì§€ì , DDIMê³¼ high-order numerical samplingì˜ ì¥ì ì„ ê²°í•©í•˜ì—¬ ìƒˆë¡œìš´ sampling ë°©ì‹ì„ ì œì‹œ.
stable diffusionì—ì„œ ì‚¬ìš©ëœ samplingë°©ì‹ì´ê³  ì„±ëŠ¥ì´ ì¢‹ë‹¤.

**gDDIM: Generalized denoising diffusion implicit models** \
*Qinsheng Zhang, Molei Tao, Yongxin Chen* \
ICLR 2023 Submission / preprint [[Paper](https://arxiv.org/abs/2206.05564)] \
[Submitted on 11 Jun 2022] \
DDPM, DDIM, ë“±ë“±ì„ ëª¨ë‘ SDEì˜ í˜•íƒœë¡œ ì „í™˜, Blur Diffusionì´ë‚˜ Critically-Damped Langevin Diffusion ê¹Œì§€ë„ SDEë¡œ í‘œí˜„í•œ ë’¤, generalí•œ formì˜ SDE -> DDIMì„ ë§Œë“œëŠ” ë°©ë²•ì„ ì œì•ˆí•œë‹¤. ì´ë¥¼ í†µí•´ istropic diffusion modelsê¹Œì§€ DDIMìœ¼ë¡œ fast sampling ê°€ëŠ¥í•˜ê²Œ í•¨. 

## Video Generation

**Video Diffusion Models** \
*Jonathan Ho, Tim Salimans, Alexey Gritsenko, William Chan, Mohammad Norouzi, David Fleet* \
arXiv 2022. [[Paper](https://arxiv.org/abs/2204.03458)] \
7 April 2022 \
Diffusionì„ ì´ìš©í•œ Video generationì„ ì²˜ìŒìœ¼ë¡œ í•œ ë…¼ë¬¸, Videoì˜ ê¸¸ì´ë¥¼ ëŠ˜ë¦¬ê³ , qualityë¥¼ ë†’ì´ëŠ” ê²ƒì— ëŒ€í•œ ë°©ë²•ì œì‹œ.

**Structure and Content-Guided Video Synthesis with Diffusion Models**\
  *Patrick Esser, Johnathan Chiu, Parmida Atighehchian, Jonathan Granskog, Anastasis Germanidis*\
  arXiv 2023. [[Paper](https://arxiv.org/abs/2302.03011)] [[Project Page](https://research.runwayml.com/gen1)]\
  [Submitted on 6 Feb 2023] \
  ë¹„ë””ì˜¤2ë¹„ë””ì˜¤ translationì„ í•  ë•Œ, ì´ë¯¸ ë˜ëŠ” í…ìŠ¤íŠ¸ë¡œ ê°€ì´ë“œë¥¼ ì£¼ëŠ” ë…¼ë¬¸. ë¹„ë””ì˜¤ì˜ timeì— ë”°ë¥¸ Spatio-temporalì„ ìœ„í•´ temporal convolution/attention ë„¤íŠ¸ì›Œí¬ë¥¼ ì‚½ì…í•˜ì˜€ê³ , structureë¥¼ ìœ ì§€ì‹œí‚¤ê¸° ìœ„í•´ depth estimation ì„ ì‚¬ìš©í•˜ì˜€ìŒ. ë˜í•œ í›ˆë ¨ë•Œ ì‚¬ìš©í•œ ë¹„ë””ì˜¤ë¥¼ CLIP image encoderì— íƒœì›Œ, ê¸°ì¡´ í…ìŠ¤íŠ¸ ëŒ€ì‹  imageë¡œ conditionì„ ì¤„ ìˆ˜ ìˆë„ë¡ í›ˆë ¨í•¨. 
  
**MagicVideo: Efficient Video Generation With Latent Diffusion Models**\
  *Daquan Zhou, Weimin Wang, Hanshu Yan, Weiwei Lv, Yizhe Zhu, Jiashi Feng*\
  arXiv 2023. [[Paper](https://arxiv.org/abs/2211.11018)] [[Project Page](https://magicvideo.github.io/#)]\
  [Submitted on 20 Nov 2022]\
  ë¹„ë””ì˜¤ë¥¼ ê°€ì§€ê³  í›ˆë ¨ì‹œí‚¤ëŠ” ë°, adaptor ë¼ëŠ” ê°œë…ì„ ì¶”ê°€í•˜ì—¬, frame ê°„ì˜ ê´€ê³„ ì •ë³´ë¥¼ ê³µìœ í•˜ë„ë¡ í•œë‹¤. ì´ ë•Œ Directed Temporal Attention ì„ ì‚¬ìš©í•´ì„œ - Masked Self attentionê³¼ ê±°ì˜ ë™ì¼í•œ ê°œë….- ë’¤ìª½ frameì—ê²Œë§Œ ì˜í–¥ì„ ë¼ì¹˜ë„ë¡ ë§Œë“¬. ë‚˜ì˜ì§€ ì•Šì€ ë…¼ë¬¸.

## 3D

**DiffRF: Rendering-Guided 3D Radiance Field Diffusion** \
*Norman MÃ¼ller, Yawar Siddiqui, Lorenzo Porzi, Samuel Rota BulÃ², Peter Kontschieder, Matthias NieÃŸner*\
arXiv 2022. [[Paper](https://arxiv.org/abs/2212.01206)] \
2 Dec 2022 \
Diffusion ìœ¼ë¡œ 3d radiacne field generationí•œ ë…¼ë¬¸. ì´ì „ì— DreamFusionì´ë‚˜ GAUDI ì™€ ê°™ì´ diffusionìœ¼ë¡œ 3D generationí•˜ëŠ” worksì´ ìˆì—ˆì§€ë§Œ, 3d unet ì„ í™œìš©í•˜ì—¬ 3d Radiance fieldë¥¼ ì§ì ‘ denoiseí•˜ëŠ” ê²ƒì€ ì´ ì—°êµ¬ê°€ ì²˜ìŒ. ëª¨ë“  sampleì„ voxel gridë¡œ ë§Œë“¤ì–´ì•¼í•˜ëŠ” precomputationì´ í•„ìš”í•˜ë‹¤. qualityë¥¼ ë†’ì´ê¸° ìœ„í•´ 3d radiance fieldì˜ denoising network í•™ìŠµì´ì™¸ì— render ëœ 2d image ìƒì—ì„œì˜ RGB lossì™€ ë§ˆì°¬ê°€ì§€ë¡œ rendered imageë¥¼ ì²˜ë¦¬í•˜ëŠ” CNN networkë¥¼ ì¶”ê°€í•˜ì˜€ë‹¤.\

## ìˆ˜í•™ê¸°ë°˜í–¥ìƒ

**On Calibrating Diffusion Probabilistic Models**\
*Tianyu Pang, Cheng Lu, Chao Du, Min Lin, Shuicheng Yan, Zhijie Deng*\
  arXiv 2023. [[Paper](https://arxiv.org/abs/2302.10688)] [[Code](https://github.com/thudzj/Calibrated-DPMs)]\
  [Submitted on 21 Feb 2023]\
  ê° ìŠ¤í…ì—ì„œ ì˜ˆì¸¡ëœ ìŠ¤ì½”ì–´ì˜ í•©ì´ 0ì´ ë˜ì–´ì•¼ í•œë‹¤ê³  ì£¼ì¥. ì´ë¥¼ ìœ„í•´ì„œ Theorem 1ì„ ì œì•ˆí•˜ëŠ”ë°, âˆ€0â‰¤s<tâ‰¤T ì¼ë•Œ sì—ì„œ êµ¬í•œ ìŠ¤ì½”ì–´ì™€ tì—ì„œ êµ¬í•œ ìŠ¤ì½”ì–´ê°€ ê°™ë‹¤ëŠ” ë§ì„ í•œë‹¤. -(xs|xt)ì¼ë•Œ- ìš©í˜„ë‹˜ì˜ ìƒê°ì€ ì´ Theorem 1ì´ DDIMì´ ì™œ ì˜ ë™ì‘í•˜ëŠ”ì§€ ë³´ì—¬ì£¼ê³  ìˆìœ¼ë©°, gDDIMì—ì„œ ì£¼ì¥í•˜ëŠ” ë°”ì™€ë„ ì—°ê´€ëœë‹¤ê³  í‰ê°€í•˜ì‹¬. ì´ë¥¼ í™•ì¥í•˜ì—¬ x0ì˜ ìŠ¤ì½”ì–´ì˜ í‰ê· ì´ 0ì´ë‹ˆ xtì˜ ìŠ¤ì½”ì–´ì˜ í‰ê· ì´ 0ì´ì–´ì•¼ í•œë‹¤ëŠ” ì£¼ì¥ì„ í•œë‹¤. (Eq.13) ì´ê±´ ê³µê° ëª»í•˜ì…¨ë‹¤. ì´ë¥¼ ë§Œì¡±ì‹œí‚¬ ìˆ˜ ìˆëŠ” ì˜ˆíƒ€të¥¼ ìŠ¤ì½”ì–´ì— ë„£ëŠ” ë°©ë²•ì„ ì œì•ˆí–ˆê³ , ì´ë¥¼ í†µí•´ DPM-Solverì˜ ì„±ëŠ¥ì„ ëª¨ë“  NFEì—ì„œ ì˜¬ë ¸ë‹¤.

**Improving Score-based Diffusion Models by Enforcing the Underlying Score Fokker-Planck Equation**\
*Chieh-Hsin Lai, Yuhta Takida, Naoki Murata, Toshimitsu Uesaka, Yuki Mitsufuji, Stefano Ermon*\
NeurIPS 2022 Workshop. [[Paper](https://arxiv.org/abs/2210.04296)]\
Submitted on 9 Oct 2022 (v1)\
Fokker-Planck Equationsì€ ë¸Œë¼ìš´ìš´ë™ì—ì„œ í•œ ìƒ˜í”Œì˜ ì›€ì§ì„ì´ ì•„ë‹ˆë¼ ì „ì²´ distributionì´ ì–´ë–»ê²Œ ì›€ì§ì´ì§€ëŠ”ì§€ì— ê´€ë ¨ëœ ìˆ˜ì‹ì´ë‹¤. ì´ë¥¼ Eq.6ì—ì„œ ë³´ì—¬ì£¼ê³  ìˆëŠ”ë°, t~=0 ì¼ ë•Œ Fokker-Planck Equationsì— ìœ„ë°˜ë˜ëŠ” ëª¨ìŠµì´ ë³´ì—¬ì§„ë‹¤ê³  ì£¼ì¥í•œë‹¤. ì´ë¥¼ ê°ë§ˆFP í…€ì„ ê°€ì§€ê³  ì¡°ì ˆí•´ì¤˜ì„œ ë§ì¶°ì£¼ëŠ”ë°, ì‹¤í—˜ì´ ë§ì§€ëŠ” ì•Šë‹¤. ì›Œí¬ìƒµ í˜ì´í¼ì´ë‹¤.

## ê¸°íƒ€

**Human Motion Diffusion Model** \
*Guy Tevet, Sigal Raab, Brian Gordon, Yonatan Shafir, Daniel Cohen-Or, Amit H. Bermano* \
arXiv 2022. [[Paper](https://arxiv.org/abs/2209.14916)][[Project page](https://guytevet.github.io/mdm-page/)] \
[Submitted on 29 Sep 2022] \
ì‚¬ëŒì˜ Motionì„ ìƒì„±í•˜ëŠ”ë° Diffusionì„ ì‚¬ìš©. spatialí•œ ì •ë³´ê°€ í•„ìš”ì—†ê¸°ì— Transformerë¥¼ ì‚¬ìš©í•˜ì˜€ë‹¤. ì´ ë•Œ ëª¨ë“  xtì— ëŒ€í•˜ì—¬ ëª¨ë¸ì€ ë°”ë¡œ x0ë¥¼ ì˜ˆì¸¡í•œë‹¤. classifier-free guidanceë¥¼ 10%ë¡œ ì‚¬ìš©í•˜ì˜€ìœ¼ë©° ì´ë¥¼ í†µí•´ text-to-motion ìƒì„±ì´ ê°€ëŠ¥í•˜ë‹¤.

**PhysDiff: Physics-Guided Human Motion Diffusion Model** \
*Ye Yuan, Jiaming Song, Umar Iqbal, Arash Vahdat, Jan Kautz* \
arXiv 2022. [[Paper](https://arxiv.org/abs/2212.02500)] \
[Submitted on 5 Dec 2022] \
Motion Diffusion Modelì—ì„œ ë°œì´ ë–¨ì–´ì§€ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê°•í™”í•™ìŠµì„ ì‚¬ìš©í•¨. ìì„¸í•œê±´ íŒ¨ìŠ¤..

## ì½ì„ê²ƒë“¤

**Soft Diffusion: Score Matching for General Corruptions** \
*Giannis Daras, Mauricio Delbracio, Hossein Talebi, Alexandros G. Dimakis, Peyman Milanfar* \
arXiv 2022. [[Paper](https://arxiv.org/abs/2209.05442)] \
12 Sep 2022 \
blurì¨ Sota (ì•ˆì½ìŒ)
